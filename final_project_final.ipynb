{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Wine Dataset Machine Learning Project"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Import necessary libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
                "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, FunctionTransformer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
                "import sqlalchemy\n",
                "from sqlalchemy import create_engine\n",
                "# Install necessary packages\n",
                "%pip install dagshub mlflow\n",
                "\n",
                "import mlflow\n",
                "import mlflow.sklearn\n",
                "from sklearn.base import BaseEstimator, TransformerMixin\n",
                "\n",
                "# Install xgboost\n",
                "%pip install xgboost\n",
                "\n",
                "# Import XGBClassifier after installation\n",
                "from xgboost import XGBClassifier"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Data Preprocessing"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the dataset\n",
                "df = pd.read_csv('cleaned_wine_data.csv')\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Handle missing values if any\n",
                "# df.isnull().sum()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Exploratory Data Analysis (EDA)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Install ydata-profiling\n",
                "%pip install ydata-profiling\n",
                "\n",
                "# Import ProfileReport from ydata_profiling\n",
                "from ydata_profiling import ProfileReport\n",
                "\n",
                "# Generate a profile report using ydata_profiling\n",
                "profile = ProfileReport(df, title='Wine Dataset Profile Report')\n",
                "profile.to_notebook_iframe()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Plot the correlation matrix\n",
                "plt.figure(figsize=(12, 8))\n",
                "sns.heatmap(df.corr(), annot=True, cmap='coolwarm')\n",
                "plt.title('Correlation Matrix')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Observations"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- **Features**: List the features and their types (numerical, categorical).\n",
                "- **Distributions**: Note the distribution of each feature (normal, skewed, etc.).\n",
                "- **Capped Values**: Identify any features with capped values.\n",
                "- **Missing Values**: Check for any missing values and their proportion."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data Cleanup Tasks"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "- Handle missing values (if any).\n",
                "- Normalize or standardize numerical features.\n",
                "- Encode categorical features (if any).\n",
                "- Remove or cap outliers (if necessary)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Normalize or standardize the data if required\n",
                "scaler = StandardScaler()\n",
                "X = df.drop('Class', axis=1)\n",
                "y = df['Class']\n",
                "X_scaled = scaler.fit_transform(X)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Database Creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Convert the dataset into a 3NF database\n",
                "engine = create_engine('sqlite:///wine.db')\n",
                "df.to_sql('wine', engine, index=False, if_exists='replace')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Extract data from the database\n",
                "df_extracted = pd.read_sql('SELECT * FROM wine', engine)\n",
                "df_extracted.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Machine Learning Experiments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 55,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform train/test split with stratification\n",
                "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
                "\n",
                "# Convert the destructured values into dataframes\n",
                "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
                "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
                "y_train = pd.DataFrame(y_train, columns=['Class'])\n",
                "y_test = pd.DataFrame(y_test, columns=['Class'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #1: Preprocessing Pipeline and Logistic Regression"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Define the preprocessing pipeline\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', Pipeline(steps=[('imputer', SimpleImputer(strategy='mean')),\n",
                "                                ('scaler', StandardScaler()),\n",
                "                                ('minmax', MinMaxScaler()),\n",
                "                                ('log', FunctionTransformer(np.log1p))]), df.drop('Class', axis=1).columns)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Define the pipeline with Logistic Regression\n",
                "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                           ('classifier', LogisticRegression())])"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Perform cross-validation\n",
                "cv_results = cross_val_score(pipeline, X_train, y_train, cv=10, scoring='f1_macro')\n",
                "print(f'Cross-validation mean F1-score: {cv_results.mean()}')\n",
                "print(f'Cross-validation std F1-score: {cv_results.std()}')"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Hyperparameter tuning\n",
                "param_grid = {\n",
                "    'classifier__C': [0.1, 1, 10, 100],\n",
                "    'classifier__solver': ['liblinear', 'saga']\n",
                "}\n",
                "\n",
                "grid_search = GridSearchCV(pipeline, param_grid, cv=10, scoring='f1_macro')\n",
                "grid_search.fit(X_train, y_train)\n",
                "print(f'Best parameters: {grid_search.best_params_}')\n",
                "print(f'Best cross-validation F1-score: {grid_search.best_score_}')"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Evaluate on the test set\n",
                "best_model = grid_search.best_estimator_\n",
                "y_pred = best_model.predict(X_test)\n",
                "f1 = f1_score(y_test, y_pred, average='macro')\n",
                "conf_matrix = confusion_matrix(y_test, y_pred)\n",
                "print(f'Test set F1-score: {f1}')\n",
                "print(f'Confusion Matrix:\\n{conf_matrix}')"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "mlflow.set_tracking_uri('https://dagshub.com/username/repo_name.mlflow')\n",
                "mlflow.set_experiment('Wine Dataset Experiment')\n",
                "\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('classifier', 'Logistic Regression')\n",
                "    mlflow.log_param('best_params', grid_search.best_params_)\n",
                "    mlflow.log_metric('f1_score', f1)\n",
                "    mlflow.log_metric('TP', conf_matrix[1, 1])\n",
                "    mlflow.log_metric('TN', conf_matrix[0, 0])\n",
                "    mlflow.log_metric('FP', conf_matrix[0, 1])\n",
                "    mlflow.log_metric('FN', conf_matrix[1, 0])\n",
                "    mlflow.sklearn.log_model(best_model, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #2: Preprocessing Pipeline and Multiple Classifiers"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the classifiers\n",
                "classifiers = {\n",
                "    'Logistic Regression': LogisticRegression(),\n",
                "    'Ridge Classifier': RidgeClassifier(),\n",
                "    'Random Forest': RandomForestClassifier(),\n",
                "    'XGBClassifier': XGBClassifier()\n",
                "}\n",
                "\n",
                "# Iterate over classifiers and log results\n",
                "for name, classifier in classifiers.items():\n",
                "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
                "                               ('classifier', classifier)])\n",
                "\n",
                "    # Perform cross-validation\n",
                "    cv_results = cross_val_score(pipeline, X_train, y_train, cv=10, scoring='f1_macro')\n",
                "    print(f'{name} Cross-validation mean F1-score: {cv_results.mean()}')\n",
                "    print(f'{name} Cross-validation std F1-score: {cv_results.std()}')\n",
                "\n",
                "    # Fit the model\n",
                "    pipeline.fit(X_train, y_train)\n",
                "    y_pred = pipeline.predict(X_test)\n",
                "    f1 = f1_score(y_test, y_pred, average='macro')\n",
                "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
                "    print(f'{name} Test set F1-score: {f1}')\n",
                "    print(f'{name} Confusion Matrix:\\n{conf_matrix}')\n",
                "\n",
                "    # Log results in MLFlow on DagsHub\n",
                "    with mlflow.start_run():\n",
                "        mlflow.log_param('classifier', name)\n",
                "        mlflow.log_metric('f1_score', f1)\n",
                "        mlflow.log_metric('TP', conf_matrix[1, 1])\n",
                "        mlflow.log_metric('TN', conf_matrix[0, 0])\n",
                "        mlflow.log_metric('FP', conf_matrix[0, 1])\n",
                "        mlflow.log_metric('FN', conf_matrix[1, 0])\n",
                "        mlflow.sklearn.log_model(pipeline, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #3: Feature Engineering and Attribute Combination"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a custom transformer for feature engineering\n",
                "class FeatureEngineering(BaseEstimator, TransformerMixin):\n",
                "    def __init__(self):\n",
                "        pass\n",
                "\n",
                "    def fit(self, X, y=None):\n",
                "        return self\n",
                "\n",
                "    def transform(self, X):\n",
                "        X = X.copy()\n",
                "        # Example of feature engineering: create new features by combining existing ones\n",
                "        X['alcohol_density'] = X['alcohol'] / X['density']\n",
                "        X['total_acidity'] = X['fixed acidity'] + X['volatile acidity']\n",
                "        return X\n",
                "\n",
                "# Define the preprocessing pipeline with feature engineering\n",
                "preprocessor_with_fe = Pipeline(steps=[('feature_engineering', FeatureEngineering()),\n",
                "                                       ('scaler', StandardScaler())])\n",
                "\n",
                "# Define the pipeline with Logistic Regression\n",
                "pipeline_with_fe = Pipeline(steps=[('preprocessor', preprocessor_with_fe),\n",
                "                                   ('classifier', LogisticRegression())])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform cross-validation\n",
                "cv_results_fe = cross_val_score(pipeline_with_fe, X_train, y_train, cv=10, scoring='f1_macro')\n",
                "print(f'Feature Engineering Cross-validation mean F1-score: {cv_results_fe.mean()}')\n",
                "print(f'Feature Engineering Cross-validation std F1-score: {cv_results_fe.std()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model\n",
                "pipeline_with_fe.fit(X_train, y_train)\n",
                "y_pred_fe = pipeline_with_fe.predict(X_test)\n",
                "f1_fe = f1_score(y_test, y_pred_fe, average='macro')\n",
                "conf_matrix_fe = confusion_matrix(y_test, y_pred_fe)\n",
                "print(f'Feature Engineering Test set F1-score: {f1_fe}')\n",
                "print(f'Feature Engineering Confusion Matrix:\\n{conf_matrix_fe}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('experiment', 'Feature Engineering')\n",
                "    mlflow.log_metric('f1_score', f1_fe)\n",
                "    mlflow.log_metric('TP', conf_matrix_fe[1, 1])\n",
                "    mlflow.log_metric('TN', conf_matrix_fe[0, 0])\n",
                "    mlflow.log_metric('FP', conf_matrix_fe[0, 1])\n",
                "    mlflow.log_metric('FN', conf_matrix_fe[1, 0])\n",
                "    mlflow.sklearn.log_model(pipeline_with_fe, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #4: Perform Feature Selection"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature selection using Correlation Threshold\n",
                "corr_matrix = df.corr().abs()\n",
                "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
                "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
                "df_reduced_corr = df.drop(columns=to_drop)\n",
                "print(f'Features dropped due to high correlation: {to_drop}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature selection using Feature Importance\n",
                "model = RandomForestClassifier()\n",
                "model.fit(X_train, y_train)\n",
                "importances = model.feature_importances_\n",
                "indices = np.argsort(importances)[::-1]\n",
                "selected_features = X.columns[indices][:10]  # Select top 10 features\n",
                "df_reduced_importance = df[selected_features]\n",
                "print(f'Selected features based on importance: {selected_features}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Feature selection using Variance Threshold\n",
                "from sklearn.feature_selection import VarianceThreshold\n",
                "selector = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
                "df_reduced_variance = selector.fit_transform(X)\n",
                "print(f'Shape after variance threshold: {df_reduced_variance.shape}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('experiment', 'Feature Selection')\n",
                "    mlflow.log_param('correlation_dropped_features', to_drop)\n",
                "    mlflow.log_param('importance_selected_features', selected_features.tolist())\n",
                "    mlflow.log_param('variance_threshold_shape', df_reduced_variance.shape)\n",
                "    mlflow.sklearn.log_model(model, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #5: Use PCA for Dimensionality Reduction"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply PCA for dimensionality reduction\n",
                "from sklearn.decomposition import PCA\n",
                "\n",
                "# Standardize the data before applying PCA\n",
                "scaler = StandardScaler()\n",
                "X_scaled = scaler.fit_transform(X)\n",
                "\n",
                "# Apply PCA\n",
                "pca = PCA()\n",
                "X_pca = pca.fit_transform(X_scaled)\n",
                "\n",
                "# Create a scree plot\n",
                "plt.figure(figsize=(10, 6))\n",
                "plt.plot(np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
                "plt.xlabel('Number of Components')\n",
                "plt.ylabel('Cumulative Explained Variance')\n",
                "plt.title('Scree Plot')\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Select the number of components that explain at least 95% of the variance\n",
                "n_components = np.argmax(np.cumsum(pca.explained_variance_ratio_) >= 0.95) + 1\n",
                "print(f'Number of components selected: {n_components}')\n",
                "\n",
                "# Apply PCA with the selected number of components\n",
                "pca = PCA(n_components=n_components)\n",
                "X_reduced = pca.fit_transform(X_scaled)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform train/test split with the reduced data\n",
                "X_train_reduced, X_test_reduced, y_train, y_test = train_test_split(X_reduced, y, test_size=0.2, random_state=42, stratify=y)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the pipeline with Logistic Regression\n",
                "pipeline_pca = Pipeline(steps=[('classifier', LogisticRegression())])\n",
                "\n",
                "# Perform cross-validation\n",
                "cv_results_pca = cross_val_score(pipeline_pca, X_train_reduced, y_train, cv=10, scoring='f1_macro')\n",
                "print(f'PCA Cross-validation mean F1-score: {cv_results_pca.mean()}')\n",
                "print(f'PCA Cross-validation std F1-score: {cv_results_pca.std()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model\n",
                "pipeline_pca.fit(X_train_reduced, y_train)\n",
                "y_pred_pca = pipeline_pca.predict(X_test_reduced)\n",
                "f1_pca = f1_score(y_test, y_pred_pca, average='macro')\n",
                "conf_matrix_pca = confusion_matrix(y_test, y_pred_pca)\n",
                "print(f'PCA Test set F1-score: {f1_pca}')\n",
                "print(f'PCA Confusion Matrix:\\n{conf_matrix_pca}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('experiment', 'PCA')\n",
                "    mlflow.log_param('n_components', n_components)\n",
                "    mlflow.log_metric('f1_score', f1_pca)\n",
                "    mlflow.log_metric('TP', conf_matrix_pca[1, 1])\n",
                "    mlflow.log_metric('TN', conf_matrix_pca[0, 0])\n",
                "    mlflow.log_metric('FP', conf_matrix_pca[0, 1])\n",
                "    mlflow.log_metric('FN', conf_matrix_pca[1, 0])\n",
                "    mlflow.sklearn.log_model(pipeline_pca, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #6: Custom Experiment with Polynomial Features"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define a custom transformer for polynomial features\n",
                "from sklearn.preprocessing import PolynomialFeatures\n",
                "\n",
                "# Define the preprocessing pipeline with polynomial features\n",
                "preprocessor_poly = Pipeline(steps=[('poly', PolynomialFeatures(degree=2)),\n",
                "                                    ('scaler', StandardScaler())])\n",
                "\n",
                "# Define the pipeline with Logistic Regression\n",
                "pipeline_poly = Pipeline(steps=[('preprocessor', preprocessor_poly),\n",
                "                                ('classifier', LogisticRegression())])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform cross-validation\n",
                "cv_results_poly = cross_val_score(pipeline_poly, X_train, y_train, cv=10, scoring='f1_macro')\n",
                "print(f'Polynomial Features Cross-validation mean F1-score: {cv_results_poly.mean()}')\n",
                "print(f'Polynomial Features Cross-validation std F1-score: {cv_results_poly.std()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model\n",
                "pipeline_poly.fit(X_train, y_train)\n",
                "y_pred_poly = pipeline_poly.predict(X_test)\n",
                "f1_poly = f1_score(y_test, y_pred_poly, average='macro')\n",
                "conf_matrix_poly = confusion_matrix(y_test, y_pred_poly)\n",
                "print(f'Polynomial Features Test set F1-score: {f1_poly}')\n",
                "print(f'Polynomial Features Confusion Matrix:\\n{conf_matrix_poly}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('experiment', 'Polynomial Features')\n",
                "    mlflow.log_metric('f1_score', f1_poly)\n",
                "    mlflow.log_metric('TP', conf_matrix_poly[1, 1])\n",
                "    mlflow.log_metric('TN', conf_matrix_poly[0, 0])\n",
                "    mlflow.log_metric('FP', conf_matrix_poly[0, 1])\n",
                "    mlflow.log_metric('FN', conf_matrix_poly[1, 0])\n",
                "    mlflow.sklearn.log_model(pipeline_poly, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Experiment #7: Custom Experiment with SMOTE for Imbalanced Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Apply SMOTE for handling imbalanced data\n",
                "from imblearn.over_sampling import SMOTE\n",
                "\n",
                "# Apply SMOTE to the training data\n",
                "smote = SMOTE(random_state=42)\n",
                "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
                "\n",
                "# Define the pipeline with Logistic Regression\n",
                "pipeline_smote = Pipeline(steps=[('classifier', LogisticRegression())])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Perform cross-validation\n",
                "cv_results_smote = cross_val_score(pipeline_smote, X_train_smote, y_train_smote, cv=10, scoring='f1_macro')\n",
                "print(f'SMOTE Cross-validation mean F1-score: {cv_results_smote.mean()}')\n",
                "print(f'SMOTE Cross-validation std F1-score: {cv_results_smote.std()}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fit the model\n",
                "pipeline_smote.fit(X_train_smote, y_train_smote)\n",
                "y_pred_smote = pipeline_smote.predict(X_test)\n",
                "f1_smote = f1_score(y_test, y_pred_smote, average='macro')\n",
                "conf_matrix_smote = confusion_matrix(y_test, y_pred_smote)\n",
                "print(f'SMOTE Test set F1-score: {f1_smote}')\n",
                "print(f'SMOTE Confusion Matrix:\\n{conf_matrix_smote}')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Log results in MLFlow on DagsHub\n",
                "with mlflow.start_run():\n",
                "    mlflow.log_param('experiment', 'SMOTE')\n",
                "    mlflow.log_metric('f1_score', f1_smote)\n",
                "    mlflow.log_metric('TP', conf_matrix_smote[1, 1])\n",
                "    mlflow.log_metric('TN', conf_matrix_smote[0, 0])\n",
                "    mlflow.log_metric('FP', conf_matrix_smote[0, 1])\n",
                "    mlflow.log_metric('FN', conf_matrix_smote[1, 0])\n",
                "    mlflow.sklearn.log_model(pipeline_smote, 'model')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Compare F1-scores of Different Experiments"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect F1-scores from different experiments\n",
                "experiments = ['Logistic Regression', 'Ridge Classifier', 'Random Forest', 'XGBClassifier', 'Feature Engineering', 'PCA', 'Polynomial Features', 'SMOTE']\n",
                "f1_scores = [f1, f1_fe, f1_pca, f1_poly, f1_smote]\n",
                "\n",
                "# Plot the F1-scores\n",
                "plt.figure(figsize=(12, 6))\n",
                "sns.barplot(x=experiments, y=f1_scores)\n",
                "plt.xlabel('Experiments')\n",
                "plt.ylabel('F1-score')\n",
                "plt.title('Comparison of F1-scores across Different Experiments')\n",
                "plt.xticks(rotation=45)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Save the Final Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save the final model using joblib\n",
                "import joblib\n",
                "\n",
                "# Assuming the best model is the one from the SMOTE experiment\n",
                "joblib.dump(pipeline_smote, 'final_model.joblib')\n",
                "print('Final model saved as final_model.joblib')"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
